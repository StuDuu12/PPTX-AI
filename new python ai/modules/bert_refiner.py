# file: modules/bert_refiner.py

import torch
from transformers import T5ForConditionalGeneration, T5Tokenizer
import time

class BertContentRefiner:
    """
    Module tinh ch·ªânh n·ªôi dung slide s·ª≠ d·ª•ng model T5 v·ªõi hi·ªáu su·∫•t cao.
    - S·ª≠ d·ª•ng batch processing ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô.
    - Ph√¢n t√≠ch vƒÉn b·∫£n tr∆∞·ªõc ƒë·ªÉ quy·∫øt ƒë·ªãnh h√†nh ƒë·ªông tinh ch·ªânh.
    - Cung c·∫•p c√°c ƒë·ªÅ xu·∫•t c·∫£i thi·ªán c·ª• th·ªÉ.
    """
    def __init__(self, model_name='t5-small'):
        self.available = False
        self.model = None
        self.tokenizer = None
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.refinement_stats = {}

        try:
            print(f"üîÑ ƒêang t·∫£i model T5 ({model_name}) l√™n thi·∫øt b·ªã {self.device}...")
            start_time = time.time()
            
            # T·∫£i tokenizer v√† model
            self.tokenizer = T5Tokenizer.from_pretrained(model_name)
            self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(self.device)
            
            self.available = True
            load_time = time.time() - start_time
            print(f"‚úÖ Model T5 ƒë√£ t·∫£i th√†nh c√¥ng sau {load_time:.2f} gi√¢y.")
        except Exception as e:
            print(f"‚ùå L·ªói khi t·∫£i model T5: {e}")
            print("‚ö†Ô∏è Module tinh ch·ªânh n·ªôi dung s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.")

    def _analyze_text_quality(self, text: str) -> dict:
        """
        Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng vƒÉn b·∫£n b·∫±ng c√°c heuristic nh·∫π nh√†ng.
        Tr·∫£ v·ªÅ m·ªôt t·ª´ ƒëi·ªÉn ch·ª©a ƒëi·ªÉm ch·∫•t l∆∞·ª£ng v√† ƒë·ªÅ xu·∫•t h√†nh ƒë·ªông.
        """
        analysis = {'score': 1.0, 'action': 'none', 'reason': ''}
        
        # 1. Ph√¢n t√≠ch ƒë·ªô d√†i
        words = text.split()
        if len(words) > 40:
            analysis['score'] -= 0.3
            analysis['action'] = 'summarize'
            analysis['reason'] = 'VƒÉn b·∫£n qu√° d√†i cho m·ªôt slide, c·∫ßn r√∫t g·ªçn.'
            return analysis
            
        # 2. Ph√¢n t√≠ch s·ª± r√µ r√†ng (v√≠ d·ª• ƒë∆°n gi·∫£n)
        long_words = [w for w in words if len(w) > 12]
        if len(long_words) / len(words + [1e-5]) > 0.15: # H∆°n 15% l√† t·ª´ d√†i
            analysis['score'] -= 0.2
            analysis['action'] = 'clarify'
            analysis['reason'] = 'S·ª≠ d·ª•ng nhi·ªÅu t·ª´ ph·ª©c t·∫°p, c·∫ßn l√†m r√µ r√†ng h∆°n.'
            return analysis

        # (C√≥ th·ªÉ th√™m c√°c b∆∞·ªõc ki·ªÉm tra ng·ªØ ph√°p nh·∫π ·ªü ƒë√¢y)

        return analysis

    def refine_content_batch(self, texts: list, actions: list) -> list:
        """
        Tinh ch·ªânh m·ªôt lo·∫°t vƒÉn b·∫£n s·ª≠ d·ª•ng T5 model.
        """
        if not self.available or not texts:
            return texts

        # T·∫°o c√°c ti·ªÅn t·ªë (prefix) cho t·ª´ng h√†nh ƒë·ªông
        prefixes = {
            'summarize': 'summarize: ',
            'clarify': 'make it clear: ',
            'grammar': 'fix grammar: ',
            'none': ''
        }
        
        # Chu·∫©n b·ªã input cho model
        inputs = [prefixes[action] + text for text, action in zip(texts, actions) if action != 'none']
        if not inputs:
            return texts
            
        # Tokenize v√† ƒë∆∞a qua model
        tokenized_inputs = self.tokenizer(inputs, return_tensors="pt", padding=True, truncation=True).to(self.device)
        
        outputs = self.model.generate(
            tokenized_inputs.input_ids, 
            max_length=150, 
            num_beams=4, 
            early_stopping=True
        )
        
        # Gi·∫£i m√£ k·∫øt qu·∫£
        refined_texts = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)
        
        # √Ånh x·∫° k·∫øt qu·∫£ tr·ªü l·∫°i danh s√°ch ban ƒë·∫ßu
        final_results = []
        refined_idx = 0
        for i, action in enumerate(actions):
            if action != 'none':
                final_results.append(refined_texts[refined_idx])
                refined_idx += 1
            else:
                final_results.append(texts[i])
        
        return final_results

    def refine_content(self, data: dict) -> dict:
        """
        H√†m ch√≠nh ƒë·ªÉ tinh ch·ªânh to√†n b·ªô n·ªôi dung c·ªßa slides_data.
        """
        if not self.available:
            return data

        slides = data.get("slides", [])
        if not slides:
            return data

        # --- B∆∞·ªõc 1: Thu th·∫≠p t·∫•t c·∫£ vƒÉn b·∫£n c·∫ßn x·ª≠ l√Ω ---
        texts_to_process = []
        actions = []
        original_map = [] # ƒê·ªÉ √°nh x·∫° k·∫øt qu·∫£ tr·ªü l·∫°i

        for i, slide in enumerate(slides):
            # Tinh ch·ªânh n·ªôi dung chi ti·∫øt
            content = slide.get("content", "")
            if content:
                analysis = self._analyze_text_quality(content)
                texts_to_process.append(content)
                actions.append(analysis['action'])
                original_map.append({'slide_index': i, 'field': 'content', 'analysis': analysis})
            
            # Tinh ch·ªânh c√°c g·∫°ch ƒë·∫ßu d√≤ng (bullet points)
            bullets = slide.get("bullet_points", [])
            for j, bullet in enumerate(bullets):
                analysis = self._analyze_text_quality(bullet)
                texts_to_process.append(bullet)
                actions.append(analysis['action'])
                original_map.append({'slide_index': i, 'field': 'bullet_points', 'bullet_index': j, 'analysis': analysis})

        # --- B∆∞·ªõc 2: X·ª≠ l√Ω h√†ng lo·∫°t (Batch Processing) ---
        print(f"üß† B·∫Øt ƒë·∫ßu tinh ch·ªânh {len(texts_to_process)} ƒëo·∫°n vƒÉn b·∫£n b·∫±ng T5...")
        start_time = time.time()
        refined_texts = self.refine_content_batch(texts_to_process, actions)
        process_time = time.time() - start_time
        print(f"‚úÖ Ho√†n th√†nh tinh ch·ªânh h√†ng lo·∫°t sau {process_time:.2f} gi√¢y.")

        # --- B∆∞·ªõc 3: C·∫≠p nh·∫≠t l·∫°i d·ªØ li·ªáu v√† thu th·∫≠p s·ªë li·ªáu th·ªëng k√™ ---
        stats = {
            "total_slides": len(slides), "improved_content": 0, "improved_bullets": 0,
            "total_quality_score": 0, "method_used": f"t5-small ({self.device})"
        }
        
        # S·ª≠ d·ª•ng set ƒë·ªÉ tr√°nh ƒë·∫øm tr√πng l·∫∑p slide ƒë√£ c·∫£i thi·ªán
        improved_content_slides = set()
        improved_bullets_slides = set()

        for i, original_info in enumerate(original_map):
            original_text = texts_to_process[i]
            refined_text = refined_texts[i]
            slide_idx = original_info['slide_index']
            field = original_info['field']
            analysis = original_info['analysis']
            
            slides[slide_idx]['bert_refined'] = slides[slide_idx].get('bert_refined', False)
            slides[slide_idx]['quality_score'] = slides[slide_idx].get('quality_score', 1.0)
            slides[slide_idx]['bert_suggestions'] = slides[slide_idx].get('bert_suggestions', [])

            # N·∫øu c√≥ s·ª± thay ƒë·ªïi
            if original_text.strip() != refined_text.strip() and analysis['action'] != 'none':
                slides[slide_idx]['bert_refined'] = True
                slides[slide_idx]['bert_suggestions'].append(analysis['reason'])
                
                if field == 'content':
                    slides[slide_idx]['original_content'] = original_text
                    slides[slide_idx]['content'] = refined_text
                    improved_content_slides.add(slide_idx)
                
                elif field == 'bullet_points':
                    bullet_idx = original_info['bullet_index']
                    if 'original_bullet_points' not in slides[slide_idx]:
                        slides[slide_idx]['original_bullet_points'] = list(slides[slide_idx]['bullet_points'])
                    slides[slide_idx]['bullet_points'][bullet_idx] = refined_text
                    improved_bullets_slides.add(slide_idx)
            
            # C·∫≠p nh·∫≠t ƒëi·ªÉm ch·∫•t l∆∞·ª£ng d·ª±a tr√™n ph√¢n t√≠ch
            slides[slide_idx]['quality_score'] -= (1.0 - analysis['score'])

        # T·ªïng h·ª£p ƒëi·ªÉm ch·∫•t l∆∞·ª£ng cu·ªëi c√πng v√† s·ªë li·ªáu
        for slide in slides:
            # Chu·∫©n h√≥a ƒëi·ªÉm kh√¥ng th·∫•p h∆°n 0.1
            slide['quality_score'] = max(0.1, slide.get('quality_score', 1.0))
            stats['total_quality_score'] += slide['quality_score']

        stats['improved_content'] = len(improved_content_slides)
        stats['improved_bullets'] = len(improved_bullets_slides)
        stats['average_quality'] = stats['total_quality_score'] / len(slides) if slides else 0
        
        data['bert_refinement_stats'] = stats
        return data